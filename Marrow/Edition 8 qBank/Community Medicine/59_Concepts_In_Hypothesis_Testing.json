{
  "meta": {
    "title": "59_Concepts_In_Hypothesis_Testing",
    "url": "https://brainandscalpel.vercel.app/59-concepts-in-hypothesis-testing-614d0b1c.html",
    "scrapedAt": "2025-11-30T12:27:20.812Z"
  },
  "questions": [
    {
      "text": "What is the hypothesis which states that an apparent effect is only due to chance, called as?",
      "choices": [
        {
          "id": 1,
          "text": "Experimental hypothesis"
        },
        {
          "id": 2,
          "text": "Null hypothesis"
        },
        {
          "id": 3,
          "text": "Inferential hypothesis"
        },
        {
          "id": 4,
          "text": "Alternative hypothesis"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p>The hypothesis that an apparent effect is only due to chance is a <strong>null hypothesis.</strong> If this is rejected as false, we have an <strong>alternative hypothesis.</strong></p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2646",
      "difficulty": "easy"
    },
    {
      "text": "What is the significance level in hypothesis testing called as?",
      "choices": [
        {
          "id": 1,
          "text": "Probability level"
        },
        {
          "id": 2,
          "text": "Alpha level"
        },
        {
          "id": 3,
          "text": "Beta level"
        },
        {
          "id": 4,
          "text": "Rejection level"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p>Significance level in hypothesis testing is called <strong>alpha level (&alpha;) or criterion</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2647",
      "difficulty": "medium"
    },
    {
      "text": "What is the p value?",
      "choices": [
        {
          "id": 1,
          "text": "Probability of declaring a significant difference when there is none in reality"
        },
        {
          "id": 2,
          "text": "Probability of declaring a significant difference when it is actually present"
        },
        {
          "id": 3,
          "text": "Probability of not declaring a significant difference when actually it is not present"
        },
        {
          "id": 4,
          "text": "Probability of not declaring a significant difference when actually it is present"
        }
      ],
      "correct_choice_id": 1,
      "solution": "<p><strong>p-value</strong> can be defined as the <strong>probability </strong>of declaring a <strong>significant difference </strong>when there is<strong> none</strong> in <strong>reality</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2653",
      "difficulty": "medium"
    },
    {
      "text": "Which of the following statements is false about the p-value?",
      "choices": [
        {
          "id": 1,
          "text": "It is equal to the probability of committing a type I error"
        },
        {
          "id": 2,
          "text": "It is equal to 1–beta"
        },
        {
          "id": 3,
          "text": "It is the chance that the presence of difference is concluded when actually there may be none"
        },
        {
          "id": 4,
          "text": "When the p value is less than α, the result is statistically significant"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p>The <strong>power</strong> of a test is&nbsp;<strong>1 &ndash; beta</strong>.</p>\n<p>The <em>p</em> value is the probability that a type I error is being made. It is the chance that the presence of difference is concluded when actually there may be none. When the <strong><em>p</em></strong> value is <strong>less than &alpha;</strong>, the result is statistically <strong>significant</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2648",
      "difficulty": "medium"
    },
    {
      "text": "A randomized control trial comparing the efficacy of two chemotherapy regimens for Hodgkin's lymphoma showed that their difference is statistically significant with p < 0.001. However, in reality the two drugs do not differ in their efficacy. What type of error is this an example of?",
      "choices": [
        {
          "id": 1,
          "text": "Type I error"
        },
        {
          "id": 2,
          "text": "Type II error"
        },
        {
          "id": 3,
          "text": "Alpha II error"
        },
        {
          "id": 4,
          "text": "Beta I error"
        }
      ],
      "correct_choice_id": 1,
      "solution": "<p>This is an example of a <strong>type I error</strong>.</p>\n<p>In this scenario, let us take the <strong>null hypothesis </strong>as the<strong> efficacy </strong>of <strong>two drugs</strong> being the <strong>same</strong>, which as the question states, is <strong>true in reality</strong>. The <strong>alternative hypothesis</strong> will then be that <strong>one drug is better than the other</strong>.</p>\n<p>The questions states that p-value<strong>&nbsp;</strong>was found to be <strong>&lt; 0.001</strong>, which is statistically<strong> significant</strong> and so the <strong>null hypothesis </strong>is<strong> rejected</strong>. But we already know that the <strong>null hypothesis </strong>is<strong> true</strong> and we are forced to accept the alternative hypothesis<strong> even though it is false</strong>.</p>\n<p>When an<strong> alternative hypothesis </strong>is<strong> accepted </strong>even<strong> when it is false</strong> and the<strong> null hypothesis </strong>is<strong> true</strong>, it is called as a <strong>type I error</strong> or an alpha error or a false positive error.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2651",
      "difficulty": "easy"
    },
    {
      "text": "An investigator is conducting a study to assess the effect of a mood stabiliser on patients with bipolar I disorder. What does it mean if the difference is significant in the results?",
      "choices": [
        {
          "id": 1,
          "text": "p > 0.05 and it is likely by chance"
        },
        {
          "id": 2,
          "text": "p > 0.05 and it is unlikely by chance"
        },
        {
          "id": 3,
          "text": "p < 0.05 and it is unlikely by chance"
        },
        {
          "id": 4,
          "text": "p < 0.05 and it is likely by chance"
        }
      ],
      "correct_choice_id": 3,
      "solution": "<p>When the <strong>difference</strong> is <strong>significant</strong>, it means that the difference is <strong>unlikely</strong> by <strong>chance</strong> and <em>p</em> will be <strong>&le; 0.05.</strong></p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2655",
      "difficulty": "medium"
    },
    {
      "text": "While assessing the effect of a new intervention for type II DM, you obtain the p-value of the study as 0.023. Based on this observation, what is your inference?",
      "choices": [
        {
          "id": 1,
          "text": "Null hypothesis is accepted and the study is rejected"
        },
        {
          "id": 2,
          "text": "Null hypothesis is rejected and the study is accepted"
        },
        {
          "id": 3,
          "text": "Null hypothesis is accepted and the study is accepted"
        },
        {
          "id": 4,
          "text": "Null hypothesis is rejected and the study is also rejected"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p>By convention, if the <strong><em>p</em> value &le; 0.05</strong>, the difference is said to be <strong>statistically significant</strong>. Thus, the <strong>null hypothesis </strong>is<strong> rejected </strong>and the<strong> study </strong>is<strong> accepted</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2654",
      "difficulty": "easy"
    },
    {
      "text": "Which of the following is a false statement regarding hypothesis testing?",
      "choices": [
        {
          "id": 1,
          "text": "Alpha is the maximum tolerable probability of a type 1 error being made"
        },
        {
          "id": 2,
          "text": "Beta is the probability of a type II error"
        },
        {
          "id": 3,
          "text": "When the null hypothesis is true but rejected, it is a type II error"
        },
        {
          "id": 4,
          "text": "p value can be more or less than alpha"
        }
      ],
      "correct_choice_id": 3,
      "solution": "<p>When the <strong>null</strong> hypothesis is <strong>true</strong> but is <strong>still rejected</strong>, it is a <strong>type I error </strong>and not a type II error.<br /><strong>Type II errors</strong> are when an <strong>alternative hypothesis </strong>is<strong> rejected </strong>even though it is <strong>true</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2657",
      "difficulty": "easy"
    },
    {
      "text": "You are conducting a randomised clinical trial to see if a new drug 'A' has better efficacy than the standard drug 'B', in patients with grade III hypertension. While analysing the results of this study, you conclude that no difference exists between the two. But in reality, a difference between them truly exists. What type of error are you making?",
      "choices": [
        {
          "id": 1,
          "text": "Type I error"
        },
        {
          "id": 2,
          "text": "Type II error"
        },
        {
          "id": 3,
          "text": "Sampling error"
        },
        {
          "id": 4,
          "text": "Interpretation error"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p><strong>Type II errors</strong> are when an <strong>alternative hypothesis is rejected </strong>when<strong> it is true</strong>.</p>\n<p>In this scenario, the <strong>null hypothesis </strong>is that there is<strong> no difference</strong>&nbsp;and the <strong>alternative hypothesis </strong>is that there is<strong> a difference</strong>.</p>\n<p>We <strong>failed </strong>to<strong> reject the null hypothesis</strong> that says there is no difference, and so we are making a <strong>type II error</strong>. In other words, we have<strong> rejected </strong>the<strong> alternative hypothesis</strong> that there is an difference when <strong>it is true</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2659",
      "difficulty": "medium"
    },
    {
      "text": "Power of a study is the ability of a test to _____",
      "choices": [
        {
          "id": 1,
          "text": "Decrease type I error"
        },
        {
          "id": 2,
          "text": "Decrease beta error"
        },
        {
          "id": 3,
          "text": "Increase alpha error"
        },
        {
          "id": 4,
          "text": "Increase beta error"
        }
      ],
      "correct_choice_id": 2,
      "solution": "<p>The <strong>power</strong> of a study is its ability to avoid or <strong>decrease beta errors</strong> or <strong>type II</strong> errors.</p>\n<p>The statistical&nbsp;<strong>power</strong> of a test is represented by <strong>1 &ndash; &beta;.</strong></p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2661",
      "difficulty": "easy"
    },
    {
      "text": "A randomised control trial is being conducted in patients with direct inguinal hernia, to compare the outcomes of a new surgery 'A' and the gold standard surgery 'B'.\nThe p value of this trial is found to be 0.04. What can we conclude from this?",
      "choices": [
        {
          "id": 1,
          "text": "Type II error is small and we can accept the findings of the study"
        },
        {
          "id": 2,
          "text": "The probability of false negative conclusion that operation A is better than B is 4%"
        },
        {
          "id": 3,
          "text": "The power of the study to detect the difference between operation A and B is 96%"
        },
        {
          "id": 4,
          "text": "The probability of a false positive conclusion that operation A is better than B is 4%"
        }
      ],
      "correct_choice_id": 4,
      "solution": "<p>Since the <strong>p-value</strong> of the study is found to be<strong> 0.04</strong>, we can infer that the <strong>probability</strong> of a <strong>false positive </strong>conclusion that the operation A is better than B is <strong>4%.</strong></p>\n<p>In this scenario, the <strong><em>p</em> value is 0.04</strong> which makes it, by convention, <strong>statistically significant</strong>. We can reject the null hypothesis and <strong>accept</strong> the <strong>alternative</strong> hypothesis that operation <strong>A</strong> is <strong>better</strong> than operation <strong>B</strong>.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2662",
      "difficulty": "medium"
    },
    {
      "text": "You are an investigator conducting a statistical test. You obtain the p value as 0.01 for your study. What does this mean?",
      "choices": [
        {
          "id": 1,
          "text": "The probability of finding a significant difference is 1%"
        },
        {
          "id": 2,
          "text": "There is a 1% probability that the difference is not by chance"
        },
        {
          "id": 3,
          "text": "The difference is not significant 1% of times and significant 99% of times"
        },
        {
          "id": 4,
          "text": "The power of the test used is 99%"
        }
      ],
      "correct_choice_id": 3,
      "solution": "<p>If the <strong>p-value = 0.01, </strong>then the<strong> difference </strong>is<strong> not significant 1% of the time&nbsp;</strong>and<strong> significant 99% of the time</strong>.</p>\n<p>In other words, there is a 99% probability that the difference is not by chance and there is a 1% probability that the difference is only by chance.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MB2663",
      "difficulty": "medium"
    },
    {
      "text": "In a well-designed cancer study, similar remission rates were obtained for a new treatment (33.2%) and the usual treatment (32.2%), with the p-value being 0.04. Which of the following statements is true regarding the study?",
      "choices": [
        {
          "id": 1,
          "text": "Both the treatments are equally effective"
        },
        {
          "id": 2,
          "text": "Neither of the treatments is effective"
        },
        {
          "id": 3,
          "text": "The new treatment is more effective than the usual treatment"
        },
        {
          "id": 4,
          "text": "The information given is not adequate to compare the efficacy of the treatments"
        }
      ],
      "correct_choice_id": 3,
      "solution": "<p>As the p-value is 0.04, we can conclude that the<strong> new treatment</strong> is<strong> more effective</strong> than the usual treatment.</p>\n<p>Even though both treatments have similar rates of remission, a valid statistical test is required to determine the difference in their effectiveness. Statistically, <strong>p-value &lt; 0.05</strong> implies that the <strong>alternate</strong> hypothesis is <strong>true</strong>.</p>\n<p>In this scenario, we can consider:</p>\n<ul>\n<li>Null hypothesis: Both the treatments are equally effective (in other terms, there is no difference between the effect of the two treatments).</li>\n<li>Alternative hypothesis: New treatment is more effective than the usual treatment.</li>\n</ul>\n<p>As the <strong>p-value</strong> is <strong>0.04,</strong> which is statistically significant (&lt;0.05), the <strong>null</strong> hypothesis is <strong>rejected</strong> and the <strong>alternative </strong>hypothesis is <strong>accepted.</strong> Hence the new treatment is more effective than the usual treatment.</p><hr><h3>Related Pearl: Concepts in Hypothesis Testing</h3><p><strong>Probability value (</strong><em>p</em><strong> value)</strong></p>\n<ul>\n<li>A&nbsp;<strong>probability value</strong>&nbsp;is the&nbsp;<strong>probability of an outcome given the hypothesis</strong>.</li>\n<li>It is not the probability of the hypothesis given the outcome, although the probability of the given hypothesis is not ignored.</li>\n<li>If the&nbsp;<strong>probability of an outcome is sufficiently low</strong>, we have&nbsp;<strong>evidence that the hypothesis is false</strong>.</li>\n<li>It is also called the&nbsp;<em>p</em><strong> value</strong>.</li>\n</ul>\n<p><strong>The Null Hypothesis and Alternative Hypothesis</strong></p>\n<ul>\n<li>The <strong>hypothesis that an apparent effect or outcome is only due to chance is a null hypothesis</strong>.</li>\n<li>In other words, a null hypothesis is one where there is <strong>no difference between the specified sample and population</strong> and any observed difference is due to chance or some other error.</li>\n<li>A null hypothesis is represented by <strong>H<sub>0</sub></strong>.</li>\n<li>If the <strong>null hypothesis</strong> is <strong>rejected</strong> as false, then there is an <strong>alternative</strong> or <strong>experimental hypothesis (H<sub>A</sub>)</strong>, which is logically accepted.</li>\n</ul>\n<p><strong>Criterion or Significance Level</strong> <strong>(&alpha;) </strong></p>\n<ul>\n<li>If the probability value of an outcome is sufficiently low, then the null hypothesis is rejected.</li>\n<li>This <strong>point below which we would define the probability value as being low enough</strong> to reject the null hypothesis is called the <strong>criterion</strong> or <strong>significance level </strong>or<strong> &alpha; (alpha) level</strong>.</li>\n<li>When the null hypothesis is rejected, the effect or outcome is said to be <strong>statistically significant</strong>.</li>\n<li>By <strong>convention</strong> (but not always), the <strong>level of &alpha; is 0.05</strong>, i.e., if the probability value of an outcome is <strong>less than or equal to 0.05 (</strong><em>p</em><strong> value &le; 0.05)</strong>, then the null hypothesis is <strong>rejected</strong>.</li>\n<li>If it is <strong>greater than 0.05</strong>, then the null hypothesis is <strong>accepted</strong>.</li>\n<li>Although by convention the level of <strong>&alpha; is 0.05</strong>, it can be lower but cannot be any higher.</li>\n</ul>\n<p><strong>Type I Error</strong></p>\n<ul>\n<li>The interpretation of <strong><em>p</em> value &le; 0.05 </strong>is that an investigator can be 95% sure that the result was not obtained by chance.</li>\n<li>It also means that there is a 5% probability that the result was obtained by chance.</li>\n<li>From this, we can deduce that the <strong>null hypothesis might indeed be true even though we rejected it</strong>.</li>\n<li>This is <strong>a type I error</strong>. In other words, <strong>when an alternative hypothesis is accepted even when it is false and the null hypothesis is true</strong>, it is a <strong>type I error</strong> or <strong>false positive error</strong>.</li>\n<li>It is also called an <strong>alpha (&alpha;) error</strong> as it is <strong>related to the criterion &alpha;</strong>.</li>\n<li>The <strong>lower the &alpha; level</strong>, the <strong>lower the rate of a type I error</strong> being made.</li>\n<li>Thus, it can be said that <strong>&alpha; is the maximum tolerable probability that a type I error is being made</strong> and that the <strong>p value is the probability that a significant difference is declared when there is none</strong>.</li>\n</ul>\n<p><strong>Type II Error</strong></p>\n<ul>\n<li>The error that is made by <strong>rejecting an alternative hypothesis when it is true</strong> or <strong>failing to reject a null hypothesis when it is false</strong> is called a <strong>type II error</strong>.</li>\n<li>It is also called a <strong>false negative error </strong>and more commonly, as a <strong>beta (&beta;) error</strong>.</li>\n<li>If the null hypothesis is false, then the <strong>probability of a type II error</strong> is <strong>&beta;</strong>.</li>\n<li>The <strong>power of a statistical test</strong> is indicated by <strong>1&ndash;&beta;.</strong></li>\n</ul>\n<p><strong>Power of a Test</strong></p>\n<ul>\n<li>The <strong>power of a test</strong> is the <strong>ability</strong> of a statistical test to <strong>avoid a type II error</strong>, which depends on its <strong>ability to detect a false null hypothesis</strong>.</li>\n<li>It is <strong>equal to 1&ndash;&beta;</strong>, which is the <strong>probability that a false null hypothesis will be rejected</strong>.</li>\n<li>By <strong>convention</strong>, a test is required to have a <strong>power of 0.8</strong> (or a <strong>&beta; of 0.2</strong>) to be <strong>acceptable</strong>. This is to say that a study that has less than 80% chance of detecting a false null hypothesis is unacceptable.</li>\n<li><strong>Type I errors are easily reduced by reducing the criterion &alpha;</strong>.</li>\n<li>A <strong>test's power will increase</strong> in the following conditions:\n<ul>\n<li>If <strong>&alpha; increases</strong>, but this will increase the chance of a type I error.</li>\n<li>If the <strong>difference between </strong>the <strong>sample mean </strong>and<strong> hypothesized mean increases</strong>. This is also called <strong>effect size</strong>.</li>\n<li>If <strong>sampling error decreases</strong>.</li>\n<li>If the <strong>sample size (n) increases</strong>.</li>\n</ul>\n</li>\n</ul>",
      "question_images": [],
      "explanation_images": [],
      "explanation_video": null,
      "question_id": "MC4529",
      "difficulty": "medium"
    }
  ]
}